{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e647a813",
      "metadata": {
        "id": "e647a813"
      },
      "source": [
        "# Emotion Classification: Data Preparation\n",
        "\n",
        "In this notebook, you'll:\n",
        "\n",
        "- Upload up to 10 face images per emotion class.\n",
        "- Organize them into folders by emotion.\n",
        "- Split the dataset into training and testing sets.\n",
        "\n",
        "**Emotions to capture:** `['happy', 'sad', 'angry', 'surprised', 'neutral']`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15c308b1",
      "metadata": {
        "id": "15c308b1"
      },
      "source": [
        "## 1. Setup and Imports\n",
        "Install dependencies and import required modules:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6eac6d8f",
      "metadata": {
        "id": "6eac6d8f"
      },
      "outputs": [],
      "source": [
        "#sample\n",
        "#!pip install scikit-learn pandas\n",
        "#import os\n",
        "#from google.colab import files\n",
        "#from sklearn.model_selection import train_test_split\n",
        "#import pandas as pd\n",
        "\n",
        "# Emotion classes\n",
        "#emotions = ['happy', 'sad', 'angry', 'surprised', 'neutral']\n",
        "#data_dir = 'data'\n",
        "\n",
        "# Create data directories\n",
        "#os.makedirs(data_dir, exist_ok=True)\n",
        "#for emo in emotions:\n",
        "    #os.makedirs(os.path.join(data_dir, emo), exist_ok=True)\n",
        "#print(\"Setup complete. Data directories ready.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#All of the needed dependencies listed above\n",
        "!pip install scikit-learn pandas\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "rrYyw0Rj4xOh",
        "outputId": "2572ed84-f0dc-4e2a-f183-5322e333899e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "rrYyw0Rj4xOh",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Conecting my google drive to the notebook so i can access the images folders training data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "SUyEMuhS5Ce3",
        "outputId": "38bc5e2c-fc02-438a-a181-c5dd9b218595",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "SUyEMuhS5Ce3",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4077c610",
      "metadata": {
        "id": "4077c610"
      },
      "source": [
        "## 2. Upload Images per Emotion\n",
        "For each emotion, upload up to 10 images. After selecting files, the dialog will close."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# i uploaded the images folder to my google drive and this sets up the path to the dataset images\n",
        "data_dir = '/content/drive/MyDrive/Colab Notebooks/images'\n",
        "\n",
        "# The emotions folders\n",
        "emotions = ['happy', 'sad',  'neutral']\n"
      ],
      "metadata": {
        "id": "nA-pdAvg6g7U"
      },
      "execution_count": 9,
      "outputs": [],
      "id": "nA-pdAvg6g7U"
    },
    {
      "cell_type": "code",
      "source": [
        "for emo in emotions:\n",
        "    emo_path = os.path.join(data_dir, emo)\n",
        "    if os.path.exists(emo_path):\n",
        "        print(f\"{emo}: {len(os.listdir(emo_path))} images found.\")\n",
        "    else:\n",
        "        print(f\"{emo}: ❌ folder not found!\")\n"
      ],
      "metadata": {
        "outputId": "6a636a72-9f2e-4a09-a040-b306b4f6c669",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jHu4qe_6m1i"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "happy: 10 images found.\n",
            "sad: 10 images found.\n",
            "neutral: 10 images found.\n"
          ]
        }
      ],
      "id": "3jHu4qe_6m1i"
    },
    {
      "cell_type": "markdown",
      "id": "49008c52",
      "metadata": {
        "id": "49008c52"
      },
      "source": [
        "## 3. Prepare Train/Test Split\n",
        "Gather all image paths and labels, then split:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We gathered all image file paths and associate them with their emotion labels.\n",
        "image_paths = []\n",
        "labels = []\n",
        "\n",
        "for emo in emotions:\n",
        "    folder = os.path.join(data_dir, emo)\n",
        "    for fname in os.listdir(folder):\n",
        "        if fname.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            image_paths.append(os.path.join(folder, fname))\n",
        "            labels.append(emo)\n",
        "\n",
        "print(f\"Total images collected: {len(image_paths)}\")\n"
      ],
      "metadata": {
        "id": "sSe3ULGx67kn",
        "outputId": "67ee0e83-def7-4493-c2e0-5a91428a720a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "sSe3ULGx67kn",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images collected: 30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# splits the  data 80% train / 20% tes\n",
        "train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
        "    image_paths, labels, test_size=0.2, stratify=labels, random_state=42)\n",
        "\n",
        "print(f\"Training samples: {len(train_paths)}\")\n",
        "print(f\"Testing samples: {len(test_paths)}\")\n"
      ],
      "metadata": {
        "id": "0sdst4T67B87",
        "outputId": "8f2067e5-a88d-4971-e5d2-08b5b955680c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "0sdst4T67B87",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 24\n",
            "Testing samples: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fe37874",
      "metadata": {
        "id": "7fe37874"
      },
      "source": [
        "## 4. Save Split Lists\n",
        "Export file lists and labels to CSV for future use:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrames\n",
        "train_df = pd.DataFrame({'image_path': train_paths, 'label': train_labels})\n",
        "test_df = pd.DataFrame({'image_path': test_paths, 'label': test_labels})\n",
        "\n",
        "# Save to CSV\n",
        "train_df.to_csv('train_split.csv', index=False)\n",
        "test_df.to_csv('test_split.csv', index=False)\n",
        "\n",
        "print(\"CSV files saved successfully.\")\n"
      ],
      "metadata": {
        "id": "8bPkDl6B8Tpv",
        "outputId": "e033db6a-c864-4406-9762-8deeda3ba6d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "8bPkDl6B8Tpv",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV files saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aswer reflection in markdown\n",
        "\n",
        "1. **Hidden Bias:**  \n",
        "   Identify one scenario where your current images might lead the model to learn a spurious signal (e.g. background, lighting). How would you test for and eliminate it?\n",
        "\n",
        "2. **Edge Cases:**  \n",
        "   Describe a face or expression that your dataset likely fails to capture. What impact could that have on real-world performance, and how would you address it?\n",
        "\n",
        "3. **Generalization Strategy:**  \n",
        "   With only 10 images per class, what’s one concrete augmentation or data-collection strategy you’d use to improve robustness—and why that choice?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Kw96bB7LIlYw"
      },
      "id": "Kw96bB7LIlYw"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}